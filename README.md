# LocalLLMAudioChat

This simple python script allows you to talk via microphone with a locally running LLM server via openai api.
It uses openai whisper and if all is installed and setup does not require any internet connection.

For the audio output it uses the **unix say command**. So on a macos it's **recommended to install a high quality voice
** like siri.

Tested with very good results with LM Studio and TheBloke openhermes 2.5 mistral 16k 7B.